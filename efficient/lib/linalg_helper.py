#!/usr/bin/env python
#
# Author: Qiming Sun <osirpt.sun@gmail.com>
#

'''
Extension to scipy.linalg module
'''

import sys
import warnings
import tempfile
from functools import reduce
import numpy
np = numpy
import scipy.linalg
import h5py
from pyscf.lib import parameters
from pyscf.lib import logger
from pyscf.lib import numpy_helper
from pyscf.lib import misc

# sort by similarity has problem which flips the ordering of eigenvalues when
# the initial guess is closed to excited state.  In this situation, function
# _sort_by_similarity may mark the excited state as the first eigenvalue and
# freeze the first eigenvalue.
SORT_EIG_BY_SIMILARITY = False
# Projecting out converged eigenvectors has problems when conv_tol is loose.
# In this situation, the converged eigenvectors may be updated in the
# following iterations.  Projecting out the converged eigenvectors may lead to
# large errors to the yet converged eigenvectors.
PROJECT_OUT_CONV_EIGS = False
# default max_memory 2000 MB

def pick_real_eigs(w, vl, vr, nroots, x0):
    abs_imag = abs(w.imag)
    max_imag_tol = max(1e-5,min(abs_imag)*1.1)
    realidx = np.where((abs_imag < max_imag_tol))[0]
    idx = realidx[w[realidx].real.argsort()]
    return w[idx], vl[:,idx], vr[:,idx], idx

#def pick_real_eigs(w, v, nroots, x0):
#    # Here we pick the eigenvalues with smallest imaginary component,
#    # where we are forced to choose at least one eigenvalue.
#    abs_imag = abs(w.imag)
#    max_imag_tol = max(1e100,min(abs_imag)*1.1)
#    realidx = numpy.where((abs_imag < max_imag_tol))[0]
#    if len(realidx) < nroots:
#        idx = w.real.argsort()
#    else:
#        idx = realidx[w[realidx].real.argsort()]
#    return w[idx].real, v[:,idx].real, idx
#    #return w[idx], v[:,idx], idx

def eig(aop, ahop, xr0, xl0, precond, tol=1e-12, max_cycle=50, max_space=12,
        lindep=1e-14, max_memory=2000, dot=numpy.dot, callback=None,
        nroots=1, lessio=True, pick=pick_real_eigs,
        verbose=logger.WARN, follow_state=False):
    '''Davidson diagonalization to solve the non-symmetric eigenvalue problem

    Args:
        aop : function([x]) => [array_like_x]
            Matrix vector multiplication :math:`y_{ki} = \sum_{j}a_{ij}*x_{jk}`.
        ahop : function([x]) => [array_like_x]
            Matrix vector multiplication :math:`y_{ki} = \sum_{j}a_{ij}^H*x_{jk}`.
        xr0 : 1D array or a list of 1D array
            Initial guess.  The initial right guess eigenvector(s) are just used as the
            initial subspace bases.  If the subspace is smaller than "nroots",
            eg 10 roots and one initial guess, all eigenvectors are chosen as
            the eigenvectors during the iterations.  The first iteration has
            one eigenvector, the next iteration has two, the third iterastion
            has 4, ..., until the subspace size > nroots.
        xl0 : 1D Array or a list of 1D array
            Initial left guess. The initial left eigenvector(s) are just used
            as the initial subspace bases. This is treated in an identical way
            to the right initial guess, xr0.
        precond : function(dx, e, x0) => array_like_dx
            Preconditioner to generate new trial vector.
            The argument dx is a residual vector ``a*x0-e*x0``; e is the current
            eigenvalue; x0 is the current eigenvector.

    Kwargs:
        tol : float
            Convergence tolerance.
        max_cycle : int
            max number of iterations.
        max_space : int
            space size to hold trial vectors.
        lindep : float
            Linear dependency threshold.  The function is terminated when the
            smallest eigenvalue of the metric of the trial vectors is lower
            than this threshold.
        max_memory : int or float
            Allowed memory in MB.
        dot : function(x, y) => scalar
            Inner product
        callback : function(envs_dict) => None
            callback function takes one dict as the argument which is
            generated by the builtin function :func:`locals`, so that the
            callback function can access all local variables in the current
            envrionment.
        nroots : int
            Number of eigenvalues to be computed.  When nroots > 1, it affects
            the shape of the return value
        lessio : bool
            How to compute a*x0 for current eigenvector x0.  There are two
            ways to compute a*x0.  One is to assemble the existed a*x.  The
            other is to call aop(x0).  The default is the first method which
            needs more IO and less computational cost.  When IO is slow, the
            second method can be considered.
        pick : function(w,v,nroots) => (e[idx], w[:,idx], idx)
            Function to filter eigenvalues and eigenvectors.
        follow_state : bool
            If the solution dramatically changes in two iterations, clean the
            subspace and restart the iteration with the old solution.  It can
            help to improve numerical stability.  Default is False.

    Returns:
        conv : bool
            Converged or not
        e : list of eigenvalues
            The eigenvalues can be sorted real or complex, depending on the
            return value of ``pick`` function.
        vl : list of 1D arrays
            Left eigenvectors. Only returned if ``left=True``.
        c : list of 1D arrays
            Right eigenvectors.

    Examples:

    >>> from pyscf import lib
    >>> a = numpy.random.random((10,10))
    >>> a = a
    >>> aop = lambda xs: [numpy.dot(a,x) for x in xs]
    >>> precond = lambda dx, e, x0: dx/(a.diagonal()-e)
    >>> x0 = a[0]
    >>> e, vl, vr = lib.davidson(aop, x0, precond, nroots=2, left=True)
    >>> len(e)
    2
    '''
    res = my_davidson_nosym1(lambda xs: [aop(x) for x in xs], lambda xs: [ahop(x) for x in xs],
                          xr0, xl0, precond, tol, max_cycle, max_space, lindep,
                          max_memory, dot, callback, nroots, lessio,
                          pick, verbose, follow_state)
    e, vl, vr = res[1:]
    if nroots == 1:
        return e[0], vl[0], vr[0]
    else:
        return e, vl, vr
davidson_nosym = eig

##########################################################################################
def my_davidson_nosym1(aop, ahop, xr0, xl0, precond, tol=1e-12, max_cycle=50, max_space=12,
                    lindep=1e-14, max_memory=2000, dot=numpy.dot, callback=None,
                    nroots=1, lessio=False, pick=pick_real_eigs,
                    verbose=logger.WARN, follow_state=False):
    if isinstance(verbose, logger.Logger):
        log = verbose
    else:
        log = logger.Logger(sys.stdout, verbose)

    toloose = numpy.sqrt(tol)
    log.debug1('tol %g  toloose %g', tol, toloose)

    if isinstance(xr0, numpy.ndarray) and xr0.ndim == 1:
        xr0 = [xr0]
    if isinstance(xl0, numpy.ndarray) and xl0.ndim == 1:
        xl0 = [xl0]

    #max_cycle = min(max_cycle, x0[0].size)
    max_space = max_space + nroots * 3
    # max_space*2 for holding ax and xs, nroots*2 for holding axt and xt
    # PH - adjusted to max_space*4 for holding left and right ax & xs
    _incore = max_memory*1e6/xr0[0].nbytes > max_space*4+nroots*5
    lessio = lessio and not _incore
    log.debug1('max_cycle %d  max_space %d  max_memory %d  incore %s',
               max_cycle, max_space, max_memory, _incore)
    heff = None
    fresh_start = True
    e = 0
    vl = None
    vr = None
    conv = [False] * nroots
    emin = None

    for icyc in range(max_cycle):
        if fresh_start:
            if _incore:
                xsl = []
                ahxl= []
                axl = []
                xsr = []
                ahxr= []
                axr = []
            else:
                xsl = _Xlist()
                ahxl= _Xlist()
                axl = _Xlist()
                xsr = _Xlist()
                ahxr= _Xlist()
                axr = _Xlist()
            space = 0
            # Orthogonalize xt space because the basis of subspace xs must be orthogonal
            # but the eigenvectors x0 might not be strictly orthogonal
            xtl = None
            xtr = None
            # Orthonormalization
            xtr,xtl = _qr(xr0,xl0,dot)
            xr0,xl0 = None,None
            max_dx_last = 1e9
        elif len(xtl) > 1:
            xtr,xtl = _qr(xtr,xtl,dot)
            xtl = xtl[:40]  # 40 trial vectors at most
            xtr = xtr[:40] 

        # Calculate A*xl, A*xr, AH*xl, AH*xr
        ahxtl = ahop(xtl)
        ahxtr = ahop(xtr)
        axtl = aop(xtl)
        axtr = aop(xtr)

        # Create lists with the stuff we need
        for k in range(len(xtl)):
            xsl.append(xtl[k])
            ahxl.append(ahxtl[k])
            axl.append(axtl[k])
        for k, xri in enumerate(xtr):
            xsr.append(xtr[k])
            ahxr.append(ahxtr[k])
            axr.append(axtr[k])
        rnow = len(xtr)
        head, space = space, space+rnow

        if heff is None:  # Lazy initilize heff to determine the dtype
            heff = numpy.empty((max_space+nroots,max_space+nroots), dtype=ahxtl[0].dtype)
        else:
            heff = numpy.asarray(heff, dtype=ahxtl[0].dtype)

        elast = e
        vl_last = vl
        vr_last = vr
        conv_last = conv

        if True:
            # Try the lazy way to calculate these:
            print('\n\nxtl = {}'.format(xtl))
            Bl = np.array(xtl).T
            print('xtl = {}'.format(Bl))
            print('axtr = {}'.format(axtr))
            ABr = np.array(axtr).T
            print('Dot Shapes: {}*{}'.format(Bl.T.conj().shape,ABr.shape))
            heff[:space,:space] = np.dot(Bl.T.conj(),ABr)
            print('my heff = {}'.format(heff[:space,:space]))
        else:
            # Do it how Qiming originally did it:
            #print(np.vstack(xtl).shape)
            for i in range(rnow):
                for k in range(rnow):
                    heff[head+k,head+i] = dot(xtl[k].conj(), axtr[i])
            for i in range(head):
                axri = axr[i]
                xli = xsl[i]
                for k in range(rnow):
                    heff[head+k,i] = dot(xtl[k].conj(), axri)
                    heff[i,head+k] = dot(xli.conj(), axtr[k])
            print(heff[:space,:space])

        # Equation (5 / 7a,7b)
        w, vl, vr = scipy.linalg.eig(heff[:space,:space],left=True,right=True)
        print('Resulting Energies: {}'.format(w))
        e, vl, vr, idx = pick(w, vl, vr, nroots, locals())
        print('Resulting Energy: {}'.format(e))

        # Keep the number we want
        e = e[:nroots]
        vl = vl[:,:nroots]
        vr = vr[:,:nroots]

        # Make sure the resulting eigenvectors are biorthonormal
        for i in range(len(e)):
            print('vr {}'.format(vr[:,i]))
            print('vl {}'.format(vl[:,i]))
            vr[:,i] = vr[:,i]/np.sum(vr[:,i])
            vl[:,i] = vl[:,i]/np.dot(vl[:,i].T.conj(),vr[:,i])
            print('After Diagonalization, Biorthonormal Check: {}'.format(np.dot(vl[:,i].T.conj(),vr[:,i])))

        # Equation (7c - I made up this equation number)
        xr0 = _gen_x0(vr, xsr)
        xl0 = _gen_x0(vl, xsl)
        #print('B*C = {}.'.format(xr0))
        #print(np.dot(np.array(xtl).T,vr))

        if lessio:
            ahxl0= ahop(xl0)
            axl0 = aop(xl0)
            ahxr0= ahop(xr0)
            axr0 = aop(xr0)
        else:
            ahxl0= _gen_x0(vl,ahxl)
            axl0 = _gen_x0(vl, axl)
            ahxr0= _gen_x0(vr,ahxr)
            axr0 = _gen_x0(vr, axr)

        # What does this do? - PH should be fine I think
        elast, conv_last = _sort_elast(elast, conv_last, vr_last, vr, vl_last, vl, fresh_start)

        try:
            de = e-elast[:len(e)]
        except:
            de = e-elast

        # CHECK FOR CONVERGENCE OF NORMS?
        dxl_norm = []
        dxr_norm = []
        xtl = []
        xtr = []
        for k, ek in enumerate(e):
            # Equation 10
            xtl.append(axl0[k] - ek * xl0[k])
            xtr.append(axr0[k] - ek * xr0[k])
            dxl_norm.append(numpy.sqrt(dot(xtl[k].conj(), xtl[k]).real))
            dxr_norm.append(numpy.sqrt(dot(xtr[k].conj(), xtr[k]).real))
            if (not conv_last[k]) and (abs(de[k]) < tol) and (dxl_norm[k] < toloose) and (dxr_norm[k] < toloose):
                log.debug('root %d converged  |r|= %4.3g  e= %s  max|de|= %4.3g',
                          k, dx_norm[k], ek, de[k])
        dxr_norm = numpy.asarray(dxr_norm)
        dxl_norm = numpy.asarray(dxl_norm)
        conv = (abs(de) < tol) & (dxr_norm < toloose) & (dxl_norm < toloose)

        ax0 = None
        max_dx_norm = max(max(dxl_norm),max(dxr_norm))
        ide = numpy.argmax(abs(de))
        if all(conv):
            log.debug('converge %d %d  |r|= %4.3g  e= %s  max|de|= %4.3g',
                      icyc, space, max_dx_norm, e, de[ide])
            break
        elif (follow_state and max_dx_norm > 1 and
              max_dx_norm/max_dx_last > 3 and space > nroots*3):
            log.debug('davidson %d %d  |r|= %4.3g  e= %s  max|de|= %4.3g  lindep= %4.3g',
                      icyc, space, max_dx_norm, e, de[ide], norm_min)
            log.debug('Large |r| detected, restore to previous x0')
            xl0 = _gen_x0(vl_last, xsl)
            xr0 = _gen_x0(vr_last, xsr)
            fresh_start = True
            continue
        # END CHECK OF CONVERGENCE OF NORMS

        # remove subspace linear dependency
        # PH Might need to edit how these loops are done
        if any(((not conv[k]) and n**2>lindep) 
                 for k, n in enumerate(dxl_norm) 
                 for k, n in enumerate(dxr_norm)):
            print('Inside the loop!')
            for k, ek in enumerate(e):
                if (not conv[k]) and (dxr_norm[k]**2 > lindep) and (dxl_norm[k]**2 > lindep):
                    # Equations 9-10
                    xtl[k] = precond(xtl[k], e[0], xl0[k])
                    xtl[k] *= 1/numpy.sqrt(dot(xtl[k].conj(), xtr[k]).real)
                    xtr[k] = precond(xtr[k], e[0], xr0[k])
                    xtr[k] *= 1/numpy.sqrt(dot(xtl[k].conj(), xtr[k]).real)
                else:
                    xtl[k] = None
                    xtr[k] = None
        else:
            for k, ek in enumerate(e):
                if (dxr_norm[k]**2 > lindep) and (dxl_norm[k]**2 > lindep):
                    xtl[k] = precond(xtl[k], e[0], xl0[k])
                    xtl[k] *= 1/numpy.sqrt(dot(xtl[k].conj(), xtr[k]).real)
                    xtr[k] = precond(xtr[k], e[0], xr0[k])
                    xtr[k] *= 1/numpy.sqrt(dot(xtl[k].conj(), xtr[k]).real)
                else:
                    xtl[k] = None
                    xtr[k] = None

        xtr = [xri for xri in xtr if xri is not None]
        xtl = [xli for xli in xtl if xli is not None]

        # Orthogonalization
        for i in range(space):
            xsli = xsl[i]
            xsri = xsr[i]
            for j in range(len(xtr)):
                xrj = xtr[j]
                xlj = xtl[j]
                xrj -= xsri * dot(xsli.conj(), xrj)
                xlj -= xsli * dot(xsri.conj(), xlj)
        # Normalization
        norm_min = 1
        for i in range(len(xtr)):
            xri = xtr[i]
            xli = xtl[i]
            norm = numpy.sqrt(dot(xli.conj(), xri).real)
            if norm**2 > lindep:
                xtr[i] *= 1/norm
                xtl[i] *= 1/norm
                norm_min = min(norm_min, norm)
            else:
                xtr[i] = None
                xtl[i] = None

        xtr = [xri for xri in xtr if xri is not None]
        xtl = [xli for xli in xtl if xli is not None]

        xli = None
        xri = None
        log.debug('davidson %d %d  |r|= %4.3g  e= %s  max|de|= %4.3g  lindep= %4.3g',
                  icyc, space, max_dx_norm, e, de[ide], norm_min)

        if (len(xtr) == 0) or (len(xtl) == 0):
            log.debug('Linear dependency in trial subspace. |r| for each state %s',
                     dxr_norm)
            conv = [conv[k] or (norm < toloose) for k,norm in enumerate(dxr_norm) for k,norm in enumerate(dxl_norm)]
            break

        max_dx_last = max_dx_norm
        fresh_start = space+nroots > max_space

        if callable(callback):
            callback(locals())

    return conv, e, xl0, xr0
##########################################################################################

def _qr(xrs, xls, dot):
    norm = numpy.sqrt(dot(xls[0].conj(), xrs[0]).real)
    qls = [xls[0]/norm]
    qrs = [xrs[0]/norm]
    for i in range(1, len(xrs)):
        xli = xls[i].copy()
        qri = qrs[i].copy()
        for j in range(len(qrs)):
            xri -= qrs[j] * dot(qls[j].conj(), xri)
            xli -= qls[j] * dot(qls[j], xri.conj())
        # Figure out how to normalize correctly
        normr = np.sum(xri)
        norml = dot(xli.conj(),xri).real
        if norm > 1e-7:
            qrs.append(xri/normr)
            qls.append(xli/norml)
    # PH - Check that these are biorthonormal
    for someIter in range(len(qrs)):
        print('biorthonormal check: {}'.format(np.dot(qrs[someIter],qls[someIter])))
    return qrs, qls

def _gen_x0(v, xs):
    space, nroots = v.shape
    x0 = []
    for k in range(nroots):
        x0.append(xs[space-1] * v[space-1,k])
    for i in reversed(range(space-1)):
        xsi = xs[i]
        for k in range(nroots):
            x0[k] += v[i,k] * xsi
    return x0

def _sort_by_similarity(w, v, nroots, conv, vlast, emin=None, heff=None):
    if not any(conv) or vlast is None:
        return w[:nroots], v[:,:nroots]

    head, nroots = vlast.shape
    conv = numpy.asarray(conv[:nroots])
    ovlp = vlast[:,conv].T.conj().dot(v[:head])
    ovlp = numpy.einsum('ij,ij->j', ovlp, ovlp)
    nconv = numpy.count_nonzero(conv)
    nleft = nroots - nconv
    idx = ovlp.argsort()
    sorted_idx = numpy.zeros(nroots, dtype=int)
    sorted_idx[conv] = numpy.sort(idx[-nconv:])
    sorted_idx[~conv] = numpy.sort(idx[:-nconv])[:nleft]

    e = w[sorted_idx]
    c = v[:,sorted_idx]
    return e, c

def _sort_elast(elast, conv_last, vr_last, vr, vl_last, vl, fresh_start):
    if fresh_start:
        return elast, conv_last
    # PH - Might need to use left eigenvectors as well?
    head, nroots = vr_last.shape
    ovlp = abs(numpy.dot(vr[:head].conj().T, vr_last))
    idx = numpy.argmax(ovlp, axis=1)
    return [elast[i] for i in idx], [conv_last[i] for i in idx]


class _Xlist(list):
    def __init__(self):
        self.scr_h5 = misc.H5TmpFile()
        self.index = []

    def __getitem__(self, n):
        key = self.index[n]
        return self.scr_h5[key].value

    def append(self, x):
        key = str(len(self.index) + 1)
        if key in self.index:
            for i in range(len(self.index)+1):
                if str(i) not in self.index:
                    key = str(i)
                    break
        self.index.append(key)
        self.scr_h5[key] = x
        self.scr_h5.flush()

    def __setitem__(self, n, x):
        key = self.index[n]
        self.scr_h5[key][:] = x
        self.scr_h5.flush()

    def __len__(self):
        return len(self.index)

    def pop(self, index):
        key = self.index.pop(index)
        del(self.scr_h5[key])


if __name__ == '__main__':
    numpy.random.seed(12)
    n = 1000
    #a = numpy.random.random((n,n))
    a = numpy.arange(n*n).reshape(n,n)
    a = numpy.sin(numpy.sin(a)) + a*1e-3j
    a = a + a.T.conj() + numpy.diag(numpy.random.random(n))*10

    e,u = scipy.linalg.eigh(a)
    #a = numpy.dot(u[:,:15]*e[:15], u[:,:15].T)
    print(e[0], u[0,0])

    def aop(x):
        return numpy.dot(a, x)

    def precond(r, e0, x0):
        idx = numpy.argwhere(abs(x0)>.1).ravel()
        #idx = numpy.arange(20)
        m = idx.size
        if m > 2:
            h0 = a[idx][:,idx] - numpy.eye(m)*e0
            h0x0 = x0 / (a.diagonal() - e0)
            h0x0[idx] = numpy.linalg.solve(h0, h0x0[idx])
            h0r = r / (a.diagonal() - e0)
            h0r[idx] = numpy.linalg.solve(h0, r[idx])
            e1 = numpy.dot(x0, h0r) / numpy.dot(x0, h0x0)
            x1 = (r - e1*x0) / (a.diagonal() - e0)
            x1[idx] = numpy.linalg.solve(h0, (r-e1*x0)[idx])
            return x1
        else:
            return r / (a.diagonal() - e0)

    x0 = [a[0]/numpy.linalg.norm(a[0]),
          a[1]/numpy.linalg.norm(a[1]),
          a[2]/numpy.linalg.norm(a[2]),
          a[3]/numpy.linalg.norm(a[3])]
    e0,x0 = dsyev(aop, x0, precond, max_cycle=30, max_space=12,
                  max_memory=.0001, verbose=5, nroots=4, follow_state=True)
    print(e0[0] - e[0])
    print(e0[1] - e[1])
    print(e0[2] - e[2])
    print(e0[3] - e[3])

##########
    a = a + numpy.diag(numpy.random.random(n)+1.1)* 10
    b = numpy.random.random(n)
    def aop(x):
        return numpy.dot(a,x)
    def precond(x, *args):
        return x / a.diagonal()
    x = numpy.linalg.solve(a, b)
    x1 = dsolve(aop, b, precond, max_cycle=50)
    print(abs(x - x1).sum())
    a_diag = a.diagonal()
    log = logger.Logger(sys.stdout, 5)
    aop = lambda x: numpy.dot(a-numpy.diag(a_diag), x)/a_diag
    x1 = krylov(aop, b/a_diag, max_cycle=50, verbose=log)
    print(abs(x - x1).sum())
    x1 = krylov(aop, b/a_diag, None, max_cycle=10, verbose=log)
    x1 = krylov(aop, b/a_diag, x1, max_cycle=30, verbose=log)
    print(abs(x - x1).sum())

##########
    numpy.random.seed(12)
    n = 500
    #a = numpy.random.random((n,n))
    a = numpy.arange(n*n).reshape(n,n)
    a = numpy.sin(numpy.sin(a))
    a = a + a.T + numpy.diag(numpy.random.random(n))*10
    b = numpy.random.random((n,n))
    b = numpy.dot(b,b.T) + numpy.eye(n)*5

    def abop(x):
        return numpy.dot(numpy.asarray(x), a.T), numpy.dot(numpy.asarray(x), b.T)

    def precond(r, e0, x0):
        return r / (a.diagonal() - e0)

    e,u = scipy.linalg.eigh(a, b)
    x0 = [a[0]/numpy.linalg.norm(a[0]),
          a[1]/numpy.linalg.norm(a[1]),]
    e0,x0 = dgeev1(abop, x0, precond, type=1, max_cycle=100, max_space=18,
                   verbose=5, nroots=4)[1:]
    print(e0[0] - e[0])
    print(e0[1] - e[1])
    print(e0[2] - e[2])
    print(e0[3] - e[3])


    e,u = scipy.linalg.eigh(a, b, type=2)
    x0 = [a[0]/numpy.linalg.norm(a[0]),
          a[1]/numpy.linalg.norm(a[1]),]
    e0,x0 = dgeev1(abop, x0, precond, type=2, max_cycle=100, max_space=18,
                   verbose=5, nroots=4)[1:]
    print(e0[0] - e[0])
    print(e0[1] - e[1])
    print(e0[2] - e[2])
    print(e0[3] - e[3])

    e,u = scipy.linalg.eigh(a, b, type=2)
    x0 = [a[0]/numpy.linalg.norm(a[0]),
          a[1]/numpy.linalg.norm(a[1]),]
    abdiag = numpy.dot(a,b).diagonal().copy()
    def abop(x):
        x = numpy.asarray(x).T
        return numpy.dot(a, numpy.dot(b, x)).T.copy()
    def precond(r, e0, x0):
        return r / (abdiag-e0)
    e0, x0 = eig(abop, x0, precond, max_cycle=100, max_space=30, verbose=5,
                 nroots=4, pick=pick_real_eigs)
    print(e0[0] - e[0])
    print(e0[1] - e[1])
    print(e0[2] - e[2])
    print(e0[3] - e[3])

    e, ul, u = scipy.linalg.eig(numpy.dot(a, b), left=True)
    idx = numpy.argsort(e)
    e = e[idx]
    ul = ul[:,idx]
    u  = u [:,idx]
    u  /= numpy.linalg.norm(u, axis=0)
    ul /= numpy.linalg.norm(ul, axis=0)
    x0 = [a[0]/numpy.linalg.norm(a[0]),
          a[1]/numpy.linalg.norm(a[1]),]
    abdiag = numpy.dot(a,b).diagonal().copy()
    e0, vl, vr = eig(abop, x0, precond, max_cycle=100, max_space=30, verbose=5,
                     nroots=4, pick=pick_real_eigs, left=True)
    print(e0[0] - e[0])
    print(e0[1] - e[1])
    print(e0[2] - e[2])
    print(e0[3] - e[3])
    print((abs(vr[0]) - abs(u[:,0])).sum())
    print((abs(vr[1]) - abs(u[:,1])).sum())
    print((abs(vr[2]) - abs(u[:,2])).sum())
    print((abs(vr[3]) - abs(u[:,3])).sum())
#    print((abs(vl[0]) - abs(ul[:,0])).max())
#    print((abs(vl[1]) - abs(ul[:,1])).max())
#    print((abs(vl[2]) - abs(ul[:,2])).max())
#    print((abs(vl[3]) - abs(ul[:,3])).max())

##########
    N = 200
    neig = 4
    A = numpy.zeros((N,N))
    k = N/2
    for ii in range(N):
        i = ii+1
        for jj in range(N):
            j = jj+1
            if j <= k:
                A[ii,jj] = i*(i==j)-(i-j-k**2)
            else:
                A[ii,jj] = i*(i==j)+(i-j-k**2)
    def matvec(x):
        return numpy.dot(A,x)

    def precond(r, e0, x0):
        return (r+e0*x0) / A.diagonal()  # Converged
        #return (r+e0*x0) / (A.diagonal()-e0)  # Does not converge
        #return r / (A.diagonal()-e0)  # Does not converge
    e, c = eig(matvec, A[:,0], precond, nroots=4, verbose=5,
                   max_cycle=200,max_space=40, tol=1e-5)
    print("# davidson evals =", e)

